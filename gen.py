#!/usr/bin/env python3
"""
gen.py — emit an HVM4 synthesizer for a given grammar, depth, and spec

Usage:
  python gen.py                              # defaults: depth=2, arith spec
  python gen.py --depth 3                   # depth-3 search
  python gen.py --spec "0:0,1:2,2:6,3:12"  # custom I/O examples
  python gen.py --depth 3 > synth_d3.hvm   # save to file
  python gen.py --depth 3 | path/to/clang/main /dev/stdin -C20

Flags:
  --depth N       expression tree depth (default: 2)
  --spec X:Y,...  comma-separated input:output examples
  --grammar G     grammar to use: arith (default), twov
  --sort-spec     put most-discriminating examples first (better pruning)
"""

import sys, argparse, itertools

# ---------------------------------------------------------------------------
# Label allocator: 1-char a-z,A-Z, then 2-char a0-z9,A0-Z9, then aa-zz etc.
# All generated names are valid HVM4 labels (≤2 base64 chars ≤ 0xFFFF).
# ---------------------------------------------------------------------------
ALPHA = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
ALNUM = ALPHA + '0123456789'

def make_label_gen():
    used = set()
    # single-char pool
    single = list(ALPHA)
    # two-char pool: first char from ALPHA, second from ALNUM
    two = [a + b for a in ALPHA for b in ALNUM]
    pool = iter(single + two)
    def fresh():
        while True:
            n = next(pool)
            if n not in used:
                used.add(n)
                return n
    return fresh

# ---------------------------------------------------------------------------
# Grammars
# ---------------------------------------------------------------------------

GRAMMARS = {
    'arith': {
        'terminals': ['#Var{}', '#Num{0}', '#Num{1}', '#Num{2}', '#Num{3}'],
        'eval': [
            '@eval = λ{',
            '  #Var: λx. x',
            '  #Num: λn. λy. n',
            '  #Add: λl. λr. λ&x. (@eval(l, x) + @eval(r, x))',
            '  #Mul: λl. λr. λ&x. (@eval(l, x) * @eval(r, x))',
            '}',
        ],
        'ops': ['Add', 'Mul'],
        'eval_call': lambda var, inp: f'(@eval({var}, {inp}))',
    },
    'twov': {
        'terminals': ['#Va{}', '#Vb{}', '#Num{0}', '#Num{1}', '#Num{2}'],
        'eval': [
            '@eval = λ{',
            '  #Va:  λa. λb. a',
            '  #Vb:  λa. λb. b',
            '  #Num: λn. λa. λb. n',
            '  #Add: λl. λr. λ&a. λ&b. (@eval(l, a, b) + @eval(r, a, b))',
            '  #Mul: λl. λr. λ&a. λ&b. (@eval(l, a, b) * @eval(r, a, b))',
            '}',
        ],
        'ops': ['Add', 'Mul'],
        # for twov, inp is a tuple "a,b"
        'eval_call': lambda var, inp: f'(@eval({var}, {inp}))',
    },
}

# ---------------------------------------------------------------------------
# Code generator
# ---------------------------------------------------------------------------

def build(depth, spec, grammar_name, sort_spec):
    g = GRAMMARS[grammar_name]
    terms = g['terminals']
    ops   = g['ops']
    fresh = make_label_gen()
    out   = []

    out += [
        f'// Generated by gen.py  depth={depth}  grammar={grammar_name}',
        f'// spec: {", ".join(f"f({x})={y}" for x,y in spec)}',
        '',
        '@if = λ{ 0: λt.λf.f; _: λc.λt.λf.t }',
        '',
        *g['eval'],
        '',
    ]

    # --- Build the expression tree recursively ---
    # make_node(d) emits definitions and returns the name of the root definition.
    # Terminal sets: &L0{t0, &L1{t1, ... tn-1, tn}} with unique labels per slot.
    # Sub-trees: &S{terminal_slot, &O{#Op0{left,right}, #Op1{left,right}, ...}}

    slot_n = [0]
    node_n = [0]

    def make_terminal_set():
        n = slot_n[0]; slot_n[0] += 1
        labels = [fresh() for _ in range(len(terms) - 1)]
        chain = terms[-1]
        for t, l in zip(reversed(terms[:-1]), reversed(labels)):
            chain = f'&{l}{{{t}, {chain}}}'
        name = f'@v{n}'
        out.append(f'{name} = {chain}')
        return name

    def make_node(d):
        term = make_terminal_set()
        if d == 0:
            return term                     # leaf: just the terminal set

        children_l = make_node(d - 1)
        children_r = make_node(d - 1)

        s, o = fresh(), fresh()
        n = node_n[0]; node_n[0] += 1
        name = f'@n{n}'
        op_arms = ', '.join(f'#{op}{{{children_l}, {children_r}}}' for op in ops)
        out.append(f'{name} = &{s}{{ {term}, &{o}{{ {op_arms} }} }}')
        return name

    root = make_node(depth)
    out.append('')

    # --- Spec ---
    # Optionally reorder: most-discriminating example first.
    # Heuristic: an example (x, y) is harder to satisfy when y is large/unusual,
    # so put non-zero, non-trivial outputs first and small/zero ones last.
    if sort_spec:
        # Score: prefer non-zero outputs and outputs not achievable by constants
        def score(xy):
            x, y = xy
            # Lower score = checked earlier = more pruning
            if y == 0: return 100          # zero is easy to satisfy
            return -abs(y)                 # larger |y| → checked earlier
        spec = sorted(spec, key=score)

    n_ex = len(spec)
    ev   = g['eval_call']
    dup_labels = [fresh() for _ in range(n_ex - 1)]

    out.append('@spec = λe.')
    prev = 'e'
    for i, lbl in enumerate(dup_labels):
        src = prev if i == 0 else f'e{i}₁'
        out.append(f'  !e{i+1}&{lbl} = {src};')
        prev = f'e{i}₁'

    def get_var(i):
        return f'e{i+1}₀' if i < n_ex - 1 else f'e{n_ex-1}₁'

    checks = [f'({ev(get_var(i), x)} == {y})' for i, (x, y) in enumerate(spec)]

    chain = checks[-1]
    for c in reversed(checks[:-1]):
        chain = f'({c} .&.\n   {chain})'
    out.append(f'  {chain}')
    out.append('')

    # --- Main ---
    z = fresh()
    out += [
        '@main =',
        f'  !e&{z} = {root};',
        '  @if(@spec(e₀), e₁, &{})',
    ]

    return '\n'.join(out)


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def parse_spec(s, grammar_name):
    pairs = []
    for tok in s.split(','):
        tok = tok.strip()
        if ':' not in tok:
            sys.exit(f'spec token must be x:y, got: {tok!r}')
        a, b = tok.split(':', 1)
        pairs.append((a.strip(), int(b)))
    return pairs

def main():
    p = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
    p.add_argument('--depth',    type=int, default=2)
    p.add_argument('--grammar',  default='arith', choices=GRAMMARS)
    p.add_argument('--spec',     default='0:0,1:2,2:6,3:12')
    p.add_argument('--sort-spec', action='store_true',
                   help='put most-discriminating examples first')
    args = p.parse_args()

    spec = parse_spec(args.spec, args.grammar)
    if len(spec) < 2:
        sys.exit('need at least 2 spec examples')

    print(build(args.depth, spec, args.grammar, args.sort_spec))

if __name__ == '__main__':
    main()
